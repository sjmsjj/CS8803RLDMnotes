# Messing With Rewards

(Ng, Harada, Russel)

## Changing the reward function



## Multiplying by a scalar



## adding a scalar



## reward shaping



## shaping in RL



## Potential based shaping in RL



## State based bonuses



## potential-based shaping



## Q-LEarningn with Potentials



## Summary


