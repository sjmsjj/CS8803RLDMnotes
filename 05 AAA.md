# AAA

## Value Iteration



## Linear Programming



## Policy Iteration



## Domination



## Why does PI Work



## B-2 is monotonic



## Another Property in PI



## PI Proof



## Summary

- VI
    - Policy converges in a finite number of steps (greedy policy)
    - If we want to be epsilon close we can define the number of iterations
- LP
    - Another way to solve MDPs
    - Primal values, dual flow
- PI
    - Domination
    - Value non-deprovement / value improvement (doesn't get worse)
    - No local optima
    - Monotonicity
